# ğŸ•µï¸ DetecÃ§Ã£o de Fraudes em TransaÃ§Ãµes Financeiras

Este projeto tem como objetivo desenvolver um modelo de machine learning para **detecÃ§Ã£o de fraudes** em transaÃ§Ãµes financeiras, utilizando tÃ©cnicas de prÃ©-processamento, balanceamento de classes, validaÃ§Ã£o cruzada, tuning de hiperparÃ¢metros e calibraÃ§Ã£o de probabilidades.

---

## ğŸ“ Estrutura do Projeto

- `Projeto_Final.ipynb`: Notebook completo com todos os passos do projeto
- `README.md`: DocumentaÃ§Ã£o do projeto
- `img/`: Pasta com visualizaÃ§Ãµes salvas (grÃ¡ficos gerados durante a anÃ¡lise)

---

## ğŸ“‚ Base de Dados

A base utilizada neste projeto estÃ¡ disponÃ­vel publicamente no Google Drive:

ğŸ“¥ [Clique aqui para baixar o dataset (CSV)](https://drive.google.com/file/d/1xkM3LcbbQOfu3T_3U41siVD_f5JBWJc_/view?usp=drive_link)

ApÃ³s o download, salve o arquivo com o nome exato:

```
Base_M43_Pratique_CREDIT_CARD_FRAUD.csv
```

ğŸ“Œ Coloque o arquivo **na mesma pasta do notebook** para garantir que o `read_csv()` funcione corretamente.

---

## ğŸš€ Tecnologias e Bibliotecas Utilizadas

- Python 3.x
- Pandas, NumPy
- Scikit-learn
- LightGBM, XGBoost, RandomForest
- Imbalanced-learn (SMOTE)
- Matplotlib, Seaborn
- CalibratedClassifierCV
- RandomizedSearchCV

---

## ğŸ”„ Pipeline de Modelagem

1. **Leitura e anÃ¡lise exploratÃ³ria**
2. **CriaÃ§Ã£o de variÃ¡veis escaladas:** `Amount_Scaled`, `Time_Scaled`
3. **Balanceamento com SMOTE (0.2)**
4. **Treinamento com 3 algoritmos:**
   - RandomForest, XGBoost, LightGBM
5. **Tuning com RandomizedSearchCV**
6. **ValidaÃ§Ã£o cruzada (3 folds) com F1-score**
7. **CalibraÃ§Ã£o com CalibratedClassifierCV**
8. **AvaliaÃ§Ã£o com mÃ©tricas e grÃ¡ficos:**
   - Matriz de confusÃ£o
   - Classification report
   - Curva ROC
   - GrÃ¡ficos de densidade e dispersÃ£o

---

## ğŸ“ˆ Resultados

### ğŸ”¹ F1-score mÃ©dio por modelo (validaÃ§Ã£o cruzada):

| Modelo       | F1-score mÃ©dio |
|--------------|----------------|
| **LightGBM** | **0.9991**     |
| XGBoost      | 0.9989         |
| RandomForest | 0.9959         |

- O **LightGBM** apresentou o melhor equilÃ­brio entre desempenho e custo computacional.
- Tempo de execuÃ§Ã£o:
  - LightGBM â‰ˆ 13 minutos
  - XGBoost â‰ˆ 1h30min

---

## ğŸ“Š Exemplos de visualizaÃ§Ãµes

A seguir, algumas das visualizaÃ§Ãµes geradas para explorar os dados e validar o desempenho do modelo:

- **Pairplot:**
  ![Pairplot](img/pairplot.png)

- **DistribuiÃ§Ã£o KDE:**
  ![KDE](img/kde_distributions.png)

- **Scatterplot Time vs Amount:**
  ![Scatterplot](img/scatter_time_amount.png)

- **Matriz de ConfusÃ£o:**
  ![Confusion Matrix](img/confusion_matrix_lgbm.png)

- **Curva ROC:**
  ![ROC Curve](img/roc_curve_lgbm.png)

---

## âœ… ConclusÃ£o

O modelo final baseado em **LightGBM** mostrou-se extremamente eficaz na detecÃ§Ã£o de fraudes, com um F1-score mÃ©dio de **0.999** e performance consistente entre os folds.  
AlÃ©m disso, o tempo de execuÃ§Ã£o foi altamente vantajoso em comparaÃ§Ã£o ao XGBoost, e a calibraÃ§Ã£o de probabilidades garantiu um modelo mais confiÃ¡vel em suas previsÃµes â€” essencial para aplicaÃ§Ãµes crÃ­ticas como esta.

---

## ğŸ‘¨â€ğŸ’» Autor

**Lucas Sugahara**  
ğŸ“§ [lucassugahara.trabalho@gmail.com](mailto:lucassugahara.trabalho@gmail.com)  
ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/lucas-sugahara-767739352)

---

## ğŸ› ï¸ Como rodar este projeto

1. Clone o repositÃ³rio:

```bash
git clone https://github.com/Sugaharaa/fraud-detection.git
```

2. Instale as dependÃªncias:

```bash
pip install pandas numpy scikit-learn lightgbm xgboost imbalanced-learn matplotlib seaborn
```

3. Coloque o arquivo `.csv` baixado na mesma pasta do notebook.

4. Execute o notebook `Projeto_Final.ipynb` no Jupyter ou Colab.

---

â­ Se este projeto te ajudou ou inspirou, deixe uma estrela no repositÃ³rio!
